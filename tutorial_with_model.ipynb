{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<torch._C.Generator at 0x7f09d4483350>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "# 型アノテーション\n",
    "from typing import Iterator, List, Dict\n",
    "# AllenNLPはPyTorch上に構築されている\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "# AllenNLPでは，各トレーニングの例をインスタンスとして表現する\n",
    "# ここの例では，センテンスを含むTextFieldと対応する品詞を含むSequenceLabelFieldがある\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.fields import TextField, SequenceLabelField\n",
    "# AllenNLPを使って，ここにあるような問題を解くには，二つのクラスを実装する必要がある\n",
    "# 1つは，DatasetReaderで，データのファイルを読み込むロジックを含んでおり，インスタンスのストリームを生成する     ★実装しないといけないクラスの１つ目\n",
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "# 多くの場合は，URLからデータセットまたはモデルをロードする\n",
    "# cached_pathヘルパーは，そのようなファイルをダウンロードして，ロカールにキャッシュし，ローカルパスを返す\n",
    "# ローカルファイルパス（そのまま返される）も使える\n",
    "from allennlp.common.file_utils import cached_path\n",
    "# 単語をひとつ以上のインデックスで表現する方法はいろいろある\n",
    "# 例えば，一意の単語の語彙を維持し，各単語に対応するIDを与えることができる\n",
    "# または，一文字ごとにひとつのIDを割り当てて，各単語を一連のIDとして表すことができる\n",
    "# AllenNLPはこの表現に対して，TokenIndexer抽象化を提供している\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "# TokenIndexerはトークンをインデックスにどのように変換するかのルールを表す\n",
    "# Vocabularyは文字列から整数への対応するマッピングが含まれている\n",
    "# 例えば，TokenIndexerはトークンをcharacter IDのシーケンスとして表すように指定できる\n",
    "# その場合，Vocabularyには，マッピング｛character -> id｝が含まれる\n",
    "# この特定の例では，各トークンに一意のIDを割り当てるSingledIdTokenIndexerを使用しているので，Vocabularyにはマッピング｛character -> id｝（およびその逆のマッピング）のみが含二つめ\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "# DatasetReaderのほかに，実装する必要があるクラスはModelです        ★実装しないといけないクラスの２つ目\n",
    "# これは，テンソル入力を取り，テンソル出力のdictを生成するPyTorchモジュール\n",
    "from allennlp.models import Model\n",
    "# モデルは埋め込みレイヤ，それからLSTMに続いて，フィードフォワードレイヤに続く\n",
    "# AllenNLPは，パディングとバッチ処理，およびさまざまなユーティリティ関数をスマートに処理するこれらすべての抽象化が含まれている\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n",
    "# トレーニングと検証のデータセットの精度を追跡する必要がある\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "# トレーニングでは，データをインテリジェントにバッチ処理できるDataIteratorsが必要\n",
    "from allennlp.data.iterators import BucketIterator\n",
    "# そして，AllenNLPのフル機能のトレーナを使う\n",
    "from allennlp.training.trainer import Trainer\n",
    "# 最後に新しい入力について予測する\n",
    "# 詳しくは以下で説明する\n",
    "from allennlp.predictors import SentenceTaggerPredictor\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# まずやることは，DatasetReaderサブクラスを実装すること\n",
    "class PosDatasetReader(DatasetReader):\n",
    "    \"\"\"\n",
    "    DatasetReader for PoS tagging data, one sentence per line, like\n",
    "\n",
    "        The###DET dog###NN ate###V the###DET apple###NN\n",
    "    \"\"\"\n",
    "\n",
    "    # DatasetReaderが必要とする唯一のパラメータは，トークンをインデックスに変換する方法を指定するTokenIndexersのdict\n",
    "    # デフォルトでは，各トークンごとに単一のインデックスを生成する\n",
    "    # これは，個別のトークンごとの一意のID（これは，ほとんどのNLPタスクで使用する標準の「ワードからインデックス」へのマッピング）\n",
    "    def __init__(self, token_indexers: Dict[str, TokenIndexer] = None) -> None:\n",
    "        super().__init__(lazy=False)\n",
    "        self.token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
    "\n",
    "    # DatasetReader.text_to_instanceは，トレーニングの例（この場合は文のトークンと対応する品詞タグ）に対応する入力を受け取り，\n",
    "    # 対応するField（この場合は文のTextFieldとタグのSequenceLabelField）をインスタンス化する\n",
    "    # ラベル付けされていないデータからインスタンスを作成して，それらを予測できるようにするため，タグはオプションである\n",
    "    # （品詞タグがターゲット変数だけど，その答えをすでに持ってるから割り当てておく？みたいな感じ？答え合わせ用？？）\n",
    "    def text_to_instance(self, tokens: List[Token], tags: List[str] = None) -> Instance:\n",
    "        self.sentence_field = TextField(tokens, self.token_indexers)\n",
    "        self.fields = {\"sentence\": self.sentence_field}\n",
    "\n",
    "        if tags:\n",
    "            self.label_field = SequenceLabelField(labels=tags, sequence_field=self.sentence_field)\n",
    "            self.fields[\"labels\"] = self.label_field\n",
    "\n",
    "        return Instance(self.fields)\n",
    "    \n",
    "    # もう一つ実装する必要があるのは，_readである\n",
    "    # これは，ファイル名を受け取り，インスタンスのストリームを作成する\n",
    "    # （このクラスの作業のほとんどは text_to_instance で行われている）\n",
    "    def _read(self, file_path: str) -> Iterator[Instance]:\n",
    "        with open(file_path) as f:\n",
    "            for line in f:\n",
    "                pairs = line.strip().split()\n",
    "                sentence, tags = zip(*(pair.split(\"###\") for pair in pairs))\n",
    "                yield self.text_to_instance([Token(word) for word in sentence], tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本的に，常に実装しなければならないもう1つのクラスはModel（これは，torch.nn.Moduleのサブクラス）\n",
    "# どのように機能するかは主に実装者次第であり，ほとんどの場合，テンソル入力を取り，モデルのトレーニングに使用する損失を含むテンソル出力のdictを生成するforwardメソッドが必要\n",
    "# 上記のように，Modelは，埋め込みレイヤー，シーケンスエンコーダー，フィードフォワードネットワークで構成される\n",
    "class LstmTagger(Model):\n",
    "\n",
    "    # コンストラクタのパラメータとして，\n",
    "    # 埋め込みパラメータとシーケンスエンコーダーを渡す\n",
    "    def __init__(self,\n",
    "                 # 埋め込みレイヤは，トークンをテンソルに変換する一般的な方法を表すAllenNLP TextFieldEmbedderとして指定される\n",
    "                 # （ここでは，学習したテンソルで各一意の単語を表現したいことを知っているが，一般クラスを使用すると，たとえばELMoなどのさまざまな種類の埋め込みを簡単に試すことができる\n",
    "                 word_embeddings: TextFieldEmbedder,\n",
    "                 # 同様に，LSTMを使用したい場合でも，エンコーダーは一般的なSeq2SeqEncoderとして指定される\n",
    "                 # これにより，トランスフォーマーなどの他のシーケンスエンコーダーを簡単に試すことができる\n",
    "                 encoder: Seq2SeqEncoder,\n",
    "                 # すべてのAllenNLPモデルは，トークンからインデックスへのラベルおよびインデックスからラベルへの名前空間マッピングを含むボキャブラリも必要\n",
    "                 vocab: Vocabulary) -> None:\n",
    "        # 基本クラスのコンストラクタに語彙を渡す\n",
    "        super().__init__(vocab)\n",
    "        self.word_embeddings = word_embeddings\n",
    "        self.encoder = encoder\n",
    "\n",
    "        # フィードフォワードレイヤはパラメータとして渡されない\n",
    "        # 正しい入力次元を見つけるためにエンコーダを調べて，正しい出力次元を見つけるために語彙（特に，ラベル→インデックスマッピング）を調べることに注意）\n",
    "        self.hidden2tag = torch.nn.Linear(in_features=encoder.get_output_dim(),\n",
    "                                          out_features=vocab.get_vocab_size('labels'))\n",
    "\n",
    "        # 最後の注意点として，CategoricalAccuracyメトリックをインスタンス化すること\n",
    "        # これは，各トレーニングおよび検証エポック中に精度を追跡するために使用する\n",
    "        self.accuracy = CategoricalAccuracy()\n",
    "\n",
    "    # 次に，実際の計算が行われるフォワードを実装する\n",
    "    # データセットの各インスタンスは（他のインスタンスとバッチ処理されて）forwardに渡される\n",
    "    # forwardメソッドは入力としてテンソルのdictを期待し，それらの名前がインスタンス内のフィールドの名前であることを期待する\n",
    "    # この場合，sentenceフィールドとlabelフィールドがあるので，それに応じてforwardを構築する\n",
    "    def forward(self,\n",
    "                sentence: Dict[str, torch.Tensor],\n",
    "                labels: torch.Tensor = None) -> Dict[str, torch.Tensor]:\n",
    "\n",
    "        # AllenNLPはバッチ入力で動作するように設計されているが，入力シーケンスごとに長さが異なる．\n",
    "        # 裏では，AllenNLPが短い入力をパディングして，バッチが同じ形になるようにする\n",
    "        # つまり，パディングを除外するために，計算ではマスクを使う必要がある\n",
    "        # これは，パディングされた場所とされていない場所をに対応する0と1のテンソルを返す\n",
    "        self.mask = get_text_field_mask(sentence)\n",
    "\n",
    "        # まず，センテンス・テンソル（各センテンスはトークンIDのシーケンス）をword_embeddingsモジュールに渡す\n",
    "        # word_embeddingsモジュールは，各センテンスを埋め込みテンソルのシーケンスに変換する\n",
    "        self.embeddings = self.word_embeddings(sentence)\n",
    "\n",
    "        # 次に，埋め込みテンソル（およびマスク）をLSTMに渡す\n",
    "        # LSTMは，エンコードされた出力のシーケンスを生成する\n",
    "        self.encoder_out = self.encoder(self.embeddings, self.mask)\n",
    "\n",
    "        # 最後に，エンコードされた各出力テンソルをフィードフォワードレイヤに渡して，さまざまなタグに対応する logit を生成する\n",
    "        self.tag_logits = self.hidden2tag(self.encoder_out)\n",
    "        self.output = {\"tag_logits\": self.tag_logits}\n",
    "\n",
    "        # このモデルを実行してラベル無しデータを予測したい場合があるので，ラベルはオプションである\n",
    "        # ラベルがある場合は，それらを使用して精度メトリックを更新し，出力に含まれる「損失」を計算する\n",
    "        if labels is not None:\n",
    "            self.accuracy(self.tag_logits, labels, self.mask)\n",
    "            self.output[\"loss\"] = sequence_cross_entropy_with_logits(self.tag_logits, labels, self.mask)\n",
    "\n",
    "        return self.output\n",
    "\n",
    "    # フォワードパスごとに更新される精度メトリックを含んでいるので，そのデータを取り出す get_metrics メソッドをオーバーライドする必要がある\n",
    "    # 裏では，CategoricalAccuracyメトリックは予測の数と正しい予測の数を格納し，転送する各呼び出し中にこれらのカウントを更新する\n",
    "    # get_metricを呼び出すたびに，計算された精度が返され，（オプションで）カウントがリセットされる\n",
    "    # これにより，各エポックの精度を新たに追跡できる\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        return {\"accuracy\": self.accuracy.get_metric(reset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LstmTagger(\n  (word_embeddings): BasicTextFieldEmbedder(\n    (token_embedder_tokens): Embedding()\n  )\n  (encoder): PytorchSeq2SeqWrapper(\n    (_module): LSTM(6, 6, batch_first=True)\n  )\n  (hidden2tag): Linear(in_features=6, out_features=3, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# まず，DatasetReaderのインスタンスを作成する\n",
    "reader = PosDatasetReader()\n",
    "\n",
    "# モデルの重みを保存したので，再利用する場合は，実際にコードを使用して同じモデル構造を再作成する必要がある\n",
    "# まず，ボキャブラリを新しい変数にリロードする\n",
    "vocab = Vocabulary.from_files(\"/tmp/vocabulary\")\n",
    "\n",
    "# 次に，モデルを構築する必要がある\n",
    "# LSTMの埋め込み層と隠れ層のサイズを選択\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6\n",
    "\n",
    "# トークンを埋め込むには，インデックス名から埋め込みへのマッピングを取る BasicTextFieldEmbedder を使用する\n",
    "# DatasetReaderを定義した場所に戻ると，デフォルトのパラメータには「トークン」と呼ばれる単一のインデックスが含まれていたため，マッピングにはそのインデックスに対応する埋め込みが必要\n",
    "# Vocabulary を使用して必要な埋め込みの数を見つけて，EMBEDDING_DIMパラメータを使用して出力の次元を指定する\n",
    "# 事前学習済みの埋め込み（GloVeベクトルなど）から始めることもできるが，この小さなトイ・データセットでこれを行う必要は無い\n",
    "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
    "                            embedding_dim=EMBEDDING_DIM)\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})\n",
    "\n",
    "# 次に，シーケンスエンコーダを指定する必要がある\n",
    "# ここでのPytorchSeq2SeqWrapperが必要な点は少し残念（設定ファイルを使用する場合は気にしなくていい　→　？）\n",
    "# ここでは，組み込みのPyTorchモジュールにいくつかの機能を追加する必要がある\n",
    "# AllenNLPでは，すべてを最初にバッチ処理するので，それも指定する\n",
    "lstm = PytorchSeq2SeqWrapper(torch.nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, batch_first=True))\n",
    "\n",
    "# 次に，モデルを再作成する（別のファイルでこれをやろうとしたら，embeddingsとlstmも再インスタンス化が必要）\n",
    "model = LstmTagger(word_embeddings, lstm, vocab)\n",
    "\n",
    "# そして，モデルの状態をファイルから読み込む\n",
    "with open(\"/tmp/model.th\", 'rb') as f:\n",
    "    model.load_state_dict(torch.load(f))\n",
    "\n",
    "# ここで，ロードしたモデルを以前に使用したGPUに移動させる\n",
    "# 以前に元のモデルでword_embeddingsとlstmを移動したので，これが必要\n",
    "# モデルのパラメータはすべて同じデバイス上にある必要がある　→　別のデバイスではダメってこと？\n",
    "cuda_device = 0\n",
    "model.cuda(cuda_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['DET', 'V', 'DET', 'NN']\n"
    }
   ],
   "source": [
    "# そして，以下を実行すると同じ予測を得られます\n",
    "predictor = SentenceTaggerPredictor(model, dataset_reader=reader)\n",
    "tag_logits = predictor.predict(\"He ate the apple\")['tag_logits']\n",
    "np.testing.assert_array_almost_equal(tag_logits, tag_logits)\n",
    "\n",
    "# 実際の予測を取得するために，argmaxを使う\n",
    "tag_ids = np.argmax(tag_logits, axis=-1)\n",
    "\n",
    "# ボキャブラリを使用して予測タグを見つける\n",
    "print([model.vocab.get_token_from_index(i, 'labels') for i in tag_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "allennlp",
   "display_name": "allennlp"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}